{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d0a039",
   "metadata": {},
   "source": [
    "\n",
    "# Task 3: Clustering Analysis â€“ Customer Segmentation\n",
    "\n",
    "This notebook will:\n",
    "1. Load `customer_data.csv` (if present) **or** generate a realistic sample dataset with the required columns.\n",
    "2. Inspect and preprocess (scaling).\n",
    "3. Find optimal **K** using **Elbow (WCSS)** and **Silhouette** methods.\n",
    "4. Fit **K-Means**, assign cluster labels.\n",
    "5. Visualize:\n",
    "   - Elbow plot (WCSS vs K)  \n",
    "   - Silhouette vs K  \n",
    "   - 2D PCA scatter with centroids\n",
    "6. Export the labeled dataset to `/mnt/data/customer_data_clustered.csv`\n",
    "\n",
    "> **Expected columns** for your own data: `Customer ID`, `Age`, `Annual Income`, `Spending Score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889fff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "DATA_PATH = Path('customer_data.csv')  # looks in current working directory\n",
    "OUTPUT_PATH = Path('/mnt/data/customer_data_clustered.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load or generate dataset\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('[INFO] Loaded your customer_data.csv')\n",
    "else:\n",
    "    print('[WARN] customer_data.csv not found. Generating a realistic sample dataset...')\n",
    "    rng = np.random.RandomState(42)\n",
    "    n = 240\n",
    "    ages = np.concatenate([\n",
    "        rng.normal(24, 3, n//3),\n",
    "        rng.normal(36, 4, n//3),\n",
    "        rng.normal(52, 6, n - 2*(n//3)),\n",
    "    ]).clip(18, 70)\n",
    "\n",
    "    incomes = np.concatenate([\n",
    "        rng.normal(30_000, 6_000, n//3),\n",
    "        rng.normal(60_000, 8_000, n//3),\n",
    "        rng.normal(100_000, 12_000, n - 2*(n//3)),\n",
    "    ]).clip(10_000, 200_000)\n",
    "\n",
    "    spend = np.concatenate([\n",
    "        rng.normal(40, 10, n//3),\n",
    "        rng.normal(60, 12, n//3),\n",
    "        rng.normal(75, 10, n - 2*(n//3)),\n",
    "    ]).clip(1, 100)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Customer ID': np.arange(1, n+1),\n",
    "        'Age': ages.round().astype(int),\n",
    "        'Annual Income': incomes.round().astype(int),\n",
    "        'Spending Score': spend.round().astype(int),\n",
    "    })\n",
    "    df.to_csv(DATA_PATH, index=False)\n",
    "    print(f'[INFO] Sample dataset saved to: {DATA_PATH.resolve()}')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('--- Dataset Inspection ---')\n",
    "print('Shape:', df.shape)\n",
    "print('Missing values per column:', df.isna().sum().to_dict())\n",
    "print('Duplicates:', int(df.duplicated().sum()))\n",
    "print('\\nDtypes:')\n",
    "print(df.dtypes)\n",
    "print('\\nDescribe (numeric):')\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6549b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "feature_cols = ['Age', 'Annual Income', 'Spending Score']\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Elbow (WCSS) + Silhouette\n",
    "k_values = list(range(2, 11))\n",
    "wcss = []\n",
    "sil_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    wcss.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "# Plot: Elbow\n",
    "plt.figure()\n",
    "plt.plot(k_values, wcss, marker='o')\n",
    "plt.title('Elbow Method (WCSS vs K)')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Silhouette\n",
    "plt.figure()\n",
    "plt.plot(k_values, sil_scores, marker='o')\n",
    "plt.title('Silhouette Score vs K')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = k_values[int(np.argmax(sil_scores))]\n",
    "print(f'[INFO] Best K by silhouette: {best_k} (score={max(sil_scores):.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit final KMeans\n",
    "final_km = KMeans(n_clusters=best_k, n_init=20, random_state=42)\n",
    "cluster_labels = final_km.fit_predict(X_scaled)\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# PCA 2D scatter\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "centroids_pca = pca.transform(final_km.cluster_centers_)\n",
    "\n",
    "plt.figure()\n",
    "for c in range(best_k):\n",
    "    mask = df['Cluster'] == c\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], s=20, label=f'Cluster {c}')\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], marker='X', s=200, label='Centroids')\n",
    "plt.title(f'PCA 2D Scatter of Clusters (K={best_k})')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c943da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export labeled dataset\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f'[INFO] Clustered dataset saved to: {OUTPUT_PATH}')\n",
    "\n",
    "# Cluster summary table\n",
    "cluster_summary = df.groupby('Cluster')[feature_cols + ['Customer ID']].agg({\n",
    "    'Age': ['mean', 'median'],\n",
    "    'Annual Income': ['mean', 'median'],\n",
    "    'Spending Score': ['mean', 'median'],\n",
    "    'Customer ID': 'count'\n",
    "})\n",
    "cluster_summary.columns = [' '.join(col).strip().replace('Customer ID ', '') for col in cluster_summary.columns.values]\n",
    "cluster_summary = cluster_summary.rename(columns={'count': 'Size'})\n",
    "display(cluster_summary)\n",
    "\n",
    "# Quick recommendations\n",
    "means = df.groupby('Cluster')[feature_cols].mean().round(2)\n",
    "order_by_spend = means.sort_values('Spending Score', ascending=False).index.tolist()\n",
    "\n",
    "print('\\n--- Quick Recommendations Heuristics ---')\n",
    "if len(order_by_spend) > 0:\n",
    "    top = order_by_spend[0]\n",
    "    print(f'- Cluster {top} shows the highest average Spending Score; consider loyalty/premium focus.')\n",
    "if len(order_by_spend) > 1:\n",
    "    low = order_by_spend[-1]\n",
    "    print(f'- Cluster {low} shows the lowest Spending Score; try promos and onboarding journeys.')\n",
    "\n",
    "rich = means['Annual Income'].idxmax()\n",
    "print(f'- Cluster {rich} has the highest Annual Income; upsell premium/high-margin items.')\n",
    "\n",
    "young = means['Age'].idxmin()\n",
    "senior = means['Age'].idxmax()\n",
    "print(f'- Cluster {young} skews younger; emphasize trendy/entry products and social campaigns.')\n",
    "print(f'- Cluster {senior} skews older; highlight reliability, warranties, and value bundles.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
